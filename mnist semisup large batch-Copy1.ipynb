{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from common import find_mxnet, data, fit\n",
    "from common.util import download_file\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import gzip, struct\n",
    "from mxnet.symbol import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"train mnist\",\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--num-classes', type=int, default=10,\n",
    "                        help='the number of classes')\n",
    "fit.add_fit_args(parser)\n",
    "parser.set_defaults(\n",
    "    # train\n",
    "    gpus           = '2',\n",
    "    batch_size     = 100,\n",
    "    disp_batches   = 100,\n",
    "    num_epochs     = 20000,\n",
    "    num_examples   = 100, \n",
    "    wd             = 1e-3,\n",
    "    lr             = .001,\n",
    "    lr_factor      = .33,\n",
    "    optimizer      = 'adam',\n",
    "    lr_step_epochs = '5000,10000,15000',\n",
    ")\n",
    "args = parser.parse_args(\"\")\n",
    "unsup_multiplier = 1\n",
    "labeled_per_class = 10\n",
    "sample_seed = 47\n",
    "val_interval = 100\n",
    "num_unsup_examples = 60000\n",
    "num_sup_examples = labeled_per_class * args.num_classes\n",
    "sup_batch_size = args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5840 5656  576 3662 3626 4448 4352 5659 4106 4176]\n",
      "[1103 5635 3920 6070 6075 3763 6509 1527 1191 2650]\n",
      "[5128 5073 2352 2550  164 5421 5858 2597 1559 3745]\n",
      "[1750 1338 2470 1011 2191  774 4962 5773 6060 1810]\n",
      "[2295 5622 5409  555 5314 2464  909 3597 1125 3279]\n",
      "[5183 2728 2781 3977  345 4871 4113 1403 2388 1468]\n",
      "[5142 1629  953 4917  950  672 2646 5433 3551 5325]\n",
      "[5726 2479 1952 6120 4552 2228 2253 4124 4963 3627]\n",
      "[4854  222  260 4818 1262 3203 5607  990 5167 1794]\n",
      "[3534   41 4560 5218 4152  972 5041 2605  640 3111]\n"
     ]
    }
   ],
   "source": [
    "def read_data(label, image):\n",
    "    \"\"\"\n",
    "    download and read data into numpy\n",
    "    \"\"\"\n",
    "    base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    with gzip.open(download_file(base_url+label, os.path.join('data',label))) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(download_file(base_url+image, os.path.join('data',image)), 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return (label, image)\n",
    "\n",
    "\n",
    "def to4d(img):\n",
    "    \"\"\"\n",
    "    reshape to 4D arrays\n",
    "    \"\"\"\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "def sample_by_label(images, labels, n_per_label, num_labels, seed=None):\n",
    "    \"\"\"Extract equal number of sampels per class.\"\"\"\n",
    "    res_img = []\n",
    "    res_lbl = []\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    for i in range(num_labels):\n",
    "        a = images[labels == i]\n",
    "        \n",
    "        if n_per_label == -1:  # use all available labeled data\n",
    "            res_img.append(a)\n",
    "        else:  # use randomly chosen subset\n",
    "            choice = rng.choice(len(a), n_per_label, False)\n",
    "            print(choice)\n",
    "            r = a[choice]\n",
    "            \n",
    "            res_img.append(r)\n",
    "            \n",
    "            lbls = np.ones(n_per_label) * i\n",
    "            res_lbl.append(lbls)\n",
    "    return (res_img, res_lbl)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "create data iterator with NDArrayIter\n",
    "\"\"\"\n",
    "(train_lbl, train_img) = read_data(\n",
    "        'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
    "(val_lbl, val_img) = read_data(\n",
    "        't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
    "\n",
    "(imgs, lbls) = sample_by_label(to4d(train_img), train_lbl, labeled_per_class, 10, seed = sample_seed)\n",
    "imgs = np.vstack(imgs)\n",
    "lbls = np.hstack(lbls)\n",
    "\n",
    "train_sup = mx.io.NDArrayIter(\n",
    "    imgs, lbls, args.batch_size, shuffle=True, data_name='dataSup', label_name='labelSup')\n",
    "train_unsup = mx.io.NDArrayIter(\n",
    "    to4d(train_img), label=None, batch_size=args.batch_size, \n",
    "    shuffle=True, data_name='dataUnsup')\n",
    "val = mx.io.NDArrayIter(\n",
    "    to4d(val_img), val_lbl, args.batch_size*1) # use larger test batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Multi_mnist_iterator(mx.io.DataIter):\n",
    "    '''multi label mnist iterator'''\n",
    "\n",
    "    def __init__(self, supIterator, unsupIterator):\n",
    "        super(Multi_mnist_iterator, self).__init__()\n",
    "        self.supIterator = supIterator\n",
    "        self.unsupIterator = unsupIterator\n",
    "        self.batch_size = self.supIterator.batch_size\n",
    "        \n",
    "        self.reset_counter = 0\n",
    "        self.reset_multiplier = int(np.floor(num_unsup_examples / num_sup_examples / unsup_multiplier))\n",
    "        print(self.reset_multiplier)\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        iters = [self.supIterator.provide_data[0]]\n",
    "        \n",
    "        for i in range(unsup_multiplier):\n",
    "            d = self.unsupIterator.provide_data[0]\n",
    "            desc = mx.io.DataDesc('dataUnsup'+str(i), d.shape, d.dtype, d.layout)\n",
    "            iters.append(desc)\n",
    "        \n",
    "        return iters\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        return self.supIterator.provide_label\n",
    "\n",
    "    def hard_reset(self):\n",
    "        self.supIterator.hard_reset()\n",
    "        self.unsupIterator.hard_reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.supIterator.reset()\n",
    "        self.reset_counter = self.reset_counter + 1\n",
    "        \n",
    "        # only reset unsup iterator if all images have been traversed\n",
    "        # samples in batches are shuffled, but always in the same (shuffled) order after a reset\n",
    "        # in most cases the unsup iterator has a lot more images, so it should be reset less often\n",
    "        if self.reset_counter % self.reset_multiplier == 0:\n",
    "            self.unsupIterator.reset()\n",
    "\n",
    "    def next(self):\n",
    "        batch0 = self.supIterator.next()\n",
    "        \n",
    "        data = [batch0.data[0]]\n",
    "        \n",
    "        for i in range(unsup_multiplier):\n",
    "            batch = self.unsupIterator.next()\n",
    "            data.append(batch.data[0])\n",
    "            \n",
    "        label = batch0.label\n",
    "\n",
    "        return mx.io.DataBatch(data=data, label=label, \\\n",
    "                pad=batch0.pad, index=batch0.index)\n",
    "    \n",
    "train = Multi_mnist_iterator(train_sup, train_unsup)\n",
    "2\n",
    "#[d.asnumpy().mean() for d in train.next().data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-eef10f933616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#print(labels.asnumpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# first fullc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod' is not defined"
     ]
    }
   ],
   "source": [
    "labels = Variable('labels')\n",
    "\n",
    "equality_matrix = broadcast_equal(reshape(labels, shape=(-1,1)), labels, name=\"eqmat\")\n",
    "    \n",
    "equality_matrix = cast(equality_matrix, dtype='float32')\n",
    "\n",
    "batch=train.next()\n",
    "\n",
    "labels = batch.label[0]\n",
    "bDataSup = batch.data[0]\n",
    "bDataUnsup = batch.data[1]\n",
    "#print(equality_matrix.eval(labels=labels)[0].asnumpy()[0:10,0:10])\n",
    "#print(labels.asnumpy())\n",
    "\n",
    "c = mod.forward()\n",
    "\n",
    "# first fullc\n",
    "flatten = mx.symbol.Flatten(data=pool)\n",
    "embeddings = mx.symbol.FullyConnected(data=flatten, num_hidden=128)\n",
    "\n",
    "splitted = split(embeddings, num_outputs=2, axis=0)\n",
    "\n",
    "a = splitted[0]\n",
    "b = splitted[1]\n",
    "\n",
    "match_ab = dot(a,transpose(b),name='match_ab')\n",
    "p_ab = softmax(match_ab, name='p_ab')\n",
    "p_ba = softmax(transpose(match_ab), name='p_ba')\n",
    "p_aba = dot(p_ab, p_ba, name='p_aba')\n",
    "\n",
    "print(bDataUnsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(1, 1)):\n",
    "    conv = mx.symbol.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad)\n",
    "    act = mx.symbol.Activation(data=conv, act_type='relu')\n",
    "    return act\n",
    "\n",
    "def build_embeddings(data, nembeddings=128, add_stn=False, **kwargs):\n",
    "    if(add_stn):\n",
    "        data = mx.sym.SpatialTransformer(data=data, loc=get_loc(data), target_shape = (28,28),\n",
    "                                         transform_type=\"affine\", sampler_type=\"bilinear\")\n",
    "    # first conv\n",
    "    conv = ConvFactory(data=data, kernel=(3,3), num_filter=32)\n",
    "    conv = ConvFactory(data=conv, kernel=(3,3), num_filter=32)\n",
    "    pool = mx.symbol.Pooling(data=conv, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    conv = ConvFactory(data=pool, kernel=(3,3), num_filter=64)\n",
    "    conv = ConvFactory(data=conv, kernel=(3,3), num_filter=64)\n",
    "    pool = mx.symbol.Pooling(data=conv, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    conv = ConvFactory(data=pool, kernel=(3,3), num_filter=128)\n",
    "    conv = ConvFactory(data=conv, kernel=(3,3), num_filter=128)\n",
    "    pool = mx.symbol.Pooling(data=conv, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    \n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=nembeddings)\n",
    "    \n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getshape(tensor):\n",
    "    arg_shape, output_shape, aux_shape = tensor.infer_shape(labelSup=(128,))\n",
    "    print(output_shape)\n",
    "def getshapeData(tensor):\n",
    "    arg_shape, output_shape, aux_shape = tensor.infer_shape(\n",
    "        dataUnsup=(128,3,28,28),dataSup=(128,3,28,28))\n",
    "    print(output_shape)\n",
    "    \n",
    "def compute_visit_loss(p, visit_weight=1):\n",
    "    \n",
    "    visit_probability = mean(p, axis=(0), keepdims=True, name='visit_prob')\n",
    "    \n",
    "    t_nb = sup_batch_size * unsup_multiplier\n",
    "    \n",
    "    init = mx.initializer.Constant(t_nb)\n",
    "    t_nb = var('t_nb', init=init, dtype='float32', shape=(1))\n",
    "    \n",
    "    target = broadcast_div(ones_like(visit_probability), t_nb)\n",
    "    \n",
    "#     arg_shape, output_shape, aux_shape = visit_probability.infer_shape(\n",
    "#         dataUnsup0=(128,3,28,28),dataSup=(128,3,28,28))\n",
    "#     print(output_shape)\n",
    "#     arg_shape, output_shape, aux_shape = target.infer_shape(\n",
    "#         dataUnsup0=(128,3,28,28),dataSup=(128,3,28,28))\n",
    "#     print(output_shape)\n",
    "#     arg_shape, output_shape, aux_shape = t_nb.infer_shape()\n",
    "#     print(output_shape)\n",
    "    visit_probability = log(1e-8 + visit_probability)\n",
    "    visit_loss = SoftmaxOutput(visit_probability, target, grad_scale=visit_weight, name='visit_loss')\n",
    "    \n",
    "    return visit_loss\n",
    "    \n",
    "def compute_semisup_loss(a,b,labels,walker_weight=1., visit_weight=1.):\n",
    "    equality_matrix = broadcast_equal(reshape(labels, shape=(-1,1)), labels, name=\"eqmat\")\n",
    "    \n",
    "    equality_matrix = cast(equality_matrix, dtype='float32')\n",
    "    p_target = broadcast_div(equality_matrix,\n",
    "                             sum(equality_matrix, axis=(1), keepdims=True))\n",
    "    \n",
    "    match_ab = dot(a,b, transpose_b=True,name='match_ab')\n",
    "    p_ab = softmax(match_ab, name='p_ab')\n",
    "    p_ba = softmax(transpose(match_ab), name='p_ba')\n",
    "    p_aba = dot(p_ab, p_ba, name='p_aba')\n",
    "    \n",
    "    #todo: create walk statistics\n",
    "    \n",
    "    # softmaxOutput should be cross entropy loss: https://github.com/dmlc/mxnet/issues/1969\n",
    "    # apparently this calculates the gradient of cross entropy loss for backprop, so should\n",
    "    # be equivalent\n",
    "    \n",
    "    p_aba = log(1e-8 + p_aba, name='log_aba')\n",
    "    walker_loss = SoftmaxOutput(p_aba, p_target, name='loss_aba', grad_scale=walker_weight)\n",
    "    \n",
    "    visit_loss = compute_visit_loss(p_ab, visit_weight)\n",
    "\n",
    "    return (walker_loss, visit_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit_loss(embeddings, labels, nclasses, grad_scale=1):\n",
    "    fc1 = mx.symbol.FullyConnected(data=embeddings, num_hidden=nclasses, name='fc1')\n",
    "    softmax = mx.symbol.SoftmaxOutput(fc1, labels, name='softmax'+str(grad_scale), grad_scale=grad_scale)\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build():\n",
    "    dataSup = mx.symbol.Variable(name=\"dataSup\")\n",
    "    labelSup = mx.symbol.Variable(name='labelSup')\n",
    "    overall_loss = []\n",
    "    \n",
    "    if unsup_multiplier >= 1:\n",
    "        dataUnsup = []\n",
    "        for i in range(unsup_multiplier):\n",
    "            dataUnsup.append(Variable(name=\"dataUnsup\"+str(i)))\n",
    "\n",
    "        # concat data, feed both through the network\n",
    "        # then split it up again\n",
    "        data = concat(dataSup, *dataUnsup, dim=0)\n",
    "\n",
    "        embeddings = build_embeddings(data)\n",
    "        splitted = split(embeddings, num_outputs=(unsup_multiplier+1), axis=0, name='split')\n",
    "\n",
    "        supEmbeddings = splitted[0]\n",
    "        \n",
    "        unsupEmbeddings = []\n",
    "        for i in range(unsup_multiplier):\n",
    "            unsupEmbeddings.append(splitted[1+i])\n",
    "    \n",
    "        unsupEmbeddings = concat(*unsupEmbeddings, dim=0)\n",
    "            \n",
    "        (walker_loss, visit_loss) = compute_semisup_loss(supEmbeddings, unsupEmbeddings, labelSup, \n",
    "                                                     walker_weight=1.0, visit_weight=1.0)\n",
    "        overall_loss = [walker_loss, visit_loss]\n",
    "        \n",
    "    else:\n",
    "        supEmbeddings = build_embeddings(dataSup)\n",
    "        \n",
    "    overall_loss = [logit_loss(supEmbeddings, labelSup, 10)] + overall_loss\n",
    "    \n",
    "    return Group(overall_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Multi_Accuracy(mx.metric.EvalMetric):\n",
    "    \"\"\"Calculate accuracies of multi label\"\"\"\n",
    "\n",
    "    def __init__(self, num=None):\n",
    "        super(Multi_Accuracy, self).__init__('multi-accuracy', num)\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "\n",
    "        #for i in range(len(preds)):\n",
    "        for i in range(1):\n",
    "            pred_label = mx.nd.argmax_channel(preds[i]).asnumpy().astype('int32')\n",
    "            label = labels[0].asnumpy().astype('int32')\n",
    "\n",
    "            #mx.metric.check_label_shapes(label, pred_label)\n",
    "            \n",
    "            #print((pred_label.flat == label.flat).sum())\n",
    "            #print(len(pred_label.flat))\n",
    "\n",
    "            \n",
    "            self.sum_metric[i] += (pred_label.flat == label.flat).sum()\n",
    "            self.num_inst[i] += len(pred_label.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation metrices\n",
    "eval_metrics = Multi_Accuracy(num= 3 if unsup_multiplier >= 1 else 1)\n",
    "                    \n",
    "def fit_model(args, network, data, **kwargs):\n",
    "    \"\"\"\n",
    "    train a model\n",
    "    args : argparse returns\n",
    "    network : the symbol definition of the nerual network\n",
    "    data_loader : function that returns the train and val data iterators\n",
    "    \"\"\"\n",
    "    # kvstore\n",
    "    kv = mx.kvstore.create(args.kv_store)\n",
    "\n",
    "    # logging\n",
    "    head = '%(asctime)-15s Node[' + str(kv.rank) + '] %(message)s'\n",
    "    logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "    logging.info('start with arguments %s', args)\n",
    "    batch_size = sup_batch_size * (unsup_multiplier + 1)\n",
    "    \n",
    "\n",
    "    # data iterators\n",
    "    (train, val) = data\n",
    "    if args.test_io:\n",
    "        tic = time.time()\n",
    "        for i, batch in enumerate(train):\n",
    "            for j in batch.data:\n",
    "                j.wait_to_read()\n",
    "            if (i+1) % args.disp_batches == 0:\n",
    "                logging.info('Batch [%d]\\tSpeed: %.2f samples/sec' % (\n",
    "                    i, args.disp_batches*batch_size/(time.time()-tic)))\n",
    "                tic = time.time()\n",
    "        return\n",
    "\n",
    "    # load model\n",
    "    if 'arg_params' in kwargs and 'aux_params' in kwargs:\n",
    "        arg_params = kwargs['arg_params']\n",
    "        aux_params = kwargs['aux_params']\n",
    "    else:\n",
    "        sym, arg_params, aux_params = fit._load_model(args, kv.rank)\n",
    "        if sym is not None:\n",
    "            assert sym.tojson() == network.tojson()\n",
    "\n",
    "    # save model\n",
    "    checkpoint = fit._save_model(args, kv.rank)\n",
    "\n",
    "    # devices for training\n",
    "    devs = mx.cpu() if args.gpus is None or args.gpus is '' else [\n",
    "        mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "\n",
    "    # learning rate\n",
    "    lr, lr_scheduler = fit._get_lr_scheduler(args, kv)\n",
    "\n",
    "    data_names = ['dataSup'] + ['dataUnsup'+str(i) for i in range(unsup_multiplier)]\n",
    "        \n",
    "    # create model\n",
    "    model = mx.mod.Module(\n",
    "        context       = devs,\n",
    "        symbol        = network,\n",
    "        label_names   = ['labelSup'],\n",
    "        data_names   = data_names\n",
    "    )\n",
    "    \n",
    "    def validate_model(epoch, *args):\n",
    "        if epoch % val_interval != 0: \n",
    "            return\n",
    "        res = model.score(val, eval_metrics)\n",
    "        #TODO: pull this into default\n",
    "        for name, value in res:\n",
    "            print('Epoch[%d] Validation-%s=%f' % (epoch, name, value))\n",
    "\n",
    "    \n",
    "    #print(model.label_names)\n",
    "    lr_scheduler  = lr_scheduler\n",
    "    optimizer_params = {\n",
    "            'learning_rate': lr,\n",
    "            #'momentum' : args.mom,\n",
    "            'wd' : args.wd,\n",
    "            'rescale_grad': 1,\n",
    "            'lr_scheduler': lr_scheduler}\n",
    "\n",
    "    #monitor = mx.mon.Monitor(interval=1000, pattern='.*aba_backward.*') \n",
    "    monitor = mx.mon.Monitor(interval=1000, pattern='.*') \n",
    "    \n",
    "    #initializer = mx.init.Xavier(\n",
    "    #    rnd_type='gaussian', factor_type=\"in\", magnitude=2)\n",
    "    initializer   = mx.init.Xavier(rnd_type='gaussian', factor_type=\"avg\", magnitude=2.34)\n",
    "\n",
    "    # callbacks that run after each batch\n",
    "    batch_end_callbacks = [mx.callback.Speedometer(batch_size, args.disp_batches)]\n",
    "    \n",
    "    epoch_end_callbacks = validate_model\n",
    "\n",
    "    # run\n",
    "    model.fit(train,\n",
    "        begin_epoch        = args.load_epoch if args.load_epoch else 0,\n",
    "        num_epoch          = args.num_epochs,\n",
    "        #eval_data          = val,\n",
    "        eval_metric        = eval_metrics,\n",
    "        kvstore            = kv,\n",
    "        optimizer          = args.optimizer,\n",
    "        optimizer_params   = optimizer_params,\n",
    "        initializer        = initializer,\n",
    "        arg_params         = arg_params,\n",
    "        aux_params         = aux_params,\n",
    "        batch_end_callback = batch_end_callbacks,\n",
    "        epoch_end_callback = epoch_end_callbacks\n",
    "        #allow_missing      = True\n",
    "        #monitor            = monitor\n",
    "             )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000.0, 10000.0, 15000.0]\n",
      "Epoch[0] Validation-multi-accuracy_0=0.186700\n",
      "Epoch[0] Validation-multi-accuracy_1=nan\n",
      "Epoch[0] Validation-multi-accuracy_2=nan\n",
      "Epoch[100] Validation-multi-accuracy_0=0.920200\n",
      "Epoch[100] Validation-multi-accuracy_1=nan\n",
      "Epoch[100] Validation-multi-accuracy_2=nan\n",
      "Epoch[200] Validation-multi-accuracy_0=0.922000\n",
      "Epoch[200] Validation-multi-accuracy_1=nan\n",
      "Epoch[200] Validation-multi-accuracy_2=nan\n",
      "Epoch[300] Validation-multi-accuracy_0=0.932500\n",
      "Epoch[300] Validation-multi-accuracy_1=nan\n",
      "Epoch[300] Validation-multi-accuracy_2=nan\n",
      "Epoch[400] Validation-multi-accuracy_0=0.942300\n",
      "Epoch[400] Validation-multi-accuracy_1=nan\n",
      "Epoch[400] Validation-multi-accuracy_2=nan\n",
      "Epoch[500] Validation-multi-accuracy_0=0.947700\n",
      "Epoch[500] Validation-multi-accuracy_1=nan\n",
      "Epoch[500] Validation-multi-accuracy_2=nan\n",
      "Epoch[600] Validation-multi-accuracy_0=0.950700\n",
      "Epoch[600] Validation-multi-accuracy_1=nan\n",
      "Epoch[600] Validation-multi-accuracy_2=nan\n",
      "Epoch[700] Validation-multi-accuracy_0=0.951200\n",
      "Epoch[700] Validation-multi-accuracy_1=nan\n",
      "Epoch[700] Validation-multi-accuracy_2=nan\n",
      "Epoch[800] Validation-multi-accuracy_0=0.944100\n",
      "Epoch[800] Validation-multi-accuracy_1=nan\n",
      "Epoch[800] Validation-multi-accuracy_2=nan\n",
      "Epoch[900] Validation-multi-accuracy_0=0.954300\n",
      "Epoch[900] Validation-multi-accuracy_1=nan\n",
      "Epoch[900] Validation-multi-accuracy_2=nan\n",
      "Epoch[1000] Validation-multi-accuracy_0=0.957200\n",
      "Epoch[1000] Validation-multi-accuracy_1=nan\n",
      "Epoch[1000] Validation-multi-accuracy_2=nan\n",
      "Epoch[1100] Validation-multi-accuracy_0=0.959500\n",
      "Epoch[1100] Validation-multi-accuracy_1=nan\n",
      "Epoch[1100] Validation-multi-accuracy_2=nan\n",
      "Epoch[1200] Validation-multi-accuracy_0=0.960900\n",
      "Epoch[1200] Validation-multi-accuracy_1=nan\n",
      "Epoch[1200] Validation-multi-accuracy_2=nan\n",
      "Epoch[1300] Validation-multi-accuracy_0=0.960800\n",
      "Epoch[1300] Validation-multi-accuracy_1=nan\n",
      "Epoch[1300] Validation-multi-accuracy_2=nan\n",
      "Epoch[1400] Validation-multi-accuracy_0=0.962700\n",
      "Epoch[1400] Validation-multi-accuracy_1=nan\n",
      "Epoch[1400] Validation-multi-accuracy_2=nan\n",
      "Epoch[1500] Validation-multi-accuracy_0=0.963900\n",
      "Epoch[1500] Validation-multi-accuracy_1=nan\n",
      "Epoch[1500] Validation-multi-accuracy_2=nan\n",
      "Epoch[1600] Validation-multi-accuracy_0=0.964800\n",
      "Epoch[1600] Validation-multi-accuracy_1=nan\n",
      "Epoch[1600] Validation-multi-accuracy_2=nan\n",
      "Epoch[1700] Validation-multi-accuracy_0=0.965700\n",
      "Epoch[1700] Validation-multi-accuracy_1=nan\n",
      "Epoch[1700] Validation-multi-accuracy_2=nan\n",
      "Epoch[1800] Validation-multi-accuracy_0=0.964500\n",
      "Epoch[1800] Validation-multi-accuracy_1=nan\n",
      "Epoch[1800] Validation-multi-accuracy_2=nan\n",
      "Epoch[1900] Validation-multi-accuracy_0=0.965300\n",
      "Epoch[1900] Validation-multi-accuracy_1=nan\n",
      "Epoch[1900] Validation-multi-accuracy_2=nan\n",
      "Epoch[2000] Validation-multi-accuracy_0=0.964700\n",
      "Epoch[2000] Validation-multi-accuracy_1=nan\n",
      "Epoch[2000] Validation-multi-accuracy_2=nan\n",
      "Epoch[2100] Validation-multi-accuracy_0=0.966800\n",
      "Epoch[2100] Validation-multi-accuracy_1=nan\n",
      "Epoch[2100] Validation-multi-accuracy_2=nan\n",
      "Epoch[2200] Validation-multi-accuracy_0=0.966500\n",
      "Epoch[2200] Validation-multi-accuracy_1=nan\n",
      "Epoch[2200] Validation-multi-accuracy_2=nan\n",
      "Epoch[2300] Validation-multi-accuracy_0=0.966600\n",
      "Epoch[2300] Validation-multi-accuracy_1=nan\n",
      "Epoch[2300] Validation-multi-accuracy_2=nan\n",
      "Epoch[2400] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[2400] Validation-multi-accuracy_1=nan\n",
      "Epoch[2400] Validation-multi-accuracy_2=nan\n",
      "Epoch[2500] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[2500] Validation-multi-accuracy_1=nan\n",
      "Epoch[2500] Validation-multi-accuracy_2=nan\n",
      "Epoch[2600] Validation-multi-accuracy_0=0.966200\n",
      "Epoch[2600] Validation-multi-accuracy_1=nan\n",
      "Epoch[2600] Validation-multi-accuracy_2=nan\n",
      "Epoch[2700] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[2700] Validation-multi-accuracy_1=nan\n",
      "Epoch[2700] Validation-multi-accuracy_2=nan\n",
      "Epoch[2800] Validation-multi-accuracy_0=0.967000\n",
      "Epoch[2800] Validation-multi-accuracy_1=nan\n",
      "Epoch[2800] Validation-multi-accuracy_2=nan\n",
      "Epoch[2900] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[2900] Validation-multi-accuracy_1=nan\n",
      "Epoch[2900] Validation-multi-accuracy_2=nan\n",
      "Epoch[3000] Validation-multi-accuracy_0=0.967000\n",
      "Epoch[3000] Validation-multi-accuracy_1=nan\n",
      "Epoch[3000] Validation-multi-accuracy_2=nan\n",
      "Epoch[3100] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[3100] Validation-multi-accuracy_1=nan\n",
      "Epoch[3100] Validation-multi-accuracy_2=nan\n",
      "Epoch[3200] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[3200] Validation-multi-accuracy_1=nan\n",
      "Epoch[3200] Validation-multi-accuracy_2=nan\n",
      "Epoch[3300] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[3300] Validation-multi-accuracy_1=nan\n",
      "Epoch[3300] Validation-multi-accuracy_2=nan\n",
      "Epoch[3400] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[3400] Validation-multi-accuracy_1=nan\n",
      "Epoch[3400] Validation-multi-accuracy_2=nan\n",
      "Epoch[3500] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[3500] Validation-multi-accuracy_1=nan\n",
      "Epoch[3500] Validation-multi-accuracy_2=nan\n",
      "Epoch[3600] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[3600] Validation-multi-accuracy_1=nan\n",
      "Epoch[3600] Validation-multi-accuracy_2=nan\n",
      "Epoch[3700] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[3700] Validation-multi-accuracy_1=nan\n",
      "Epoch[3700] Validation-multi-accuracy_2=nan\n",
      "Epoch[3800] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[3800] Validation-multi-accuracy_1=nan\n",
      "Epoch[3800] Validation-multi-accuracy_2=nan\n",
      "Epoch[3900] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[3900] Validation-multi-accuracy_1=nan\n",
      "Epoch[3900] Validation-multi-accuracy_2=nan\n",
      "Epoch[4000] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[4000] Validation-multi-accuracy_1=nan\n",
      "Epoch[4000] Validation-multi-accuracy_2=nan\n",
      "Epoch[4100] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[4100] Validation-multi-accuracy_1=nan\n",
      "Epoch[4100] Validation-multi-accuracy_2=nan\n",
      "Epoch[4200] Validation-multi-accuracy_0=0.966800\n",
      "Epoch[4200] Validation-multi-accuracy_1=nan\n",
      "Epoch[4200] Validation-multi-accuracy_2=nan\n",
      "Epoch[4300] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[4300] Validation-multi-accuracy_1=nan\n",
      "Epoch[4300] Validation-multi-accuracy_2=nan\n",
      "Epoch[4400] Validation-multi-accuracy_0=0.966500\n",
      "Epoch[4400] Validation-multi-accuracy_1=nan\n",
      "Epoch[4400] Validation-multi-accuracy_2=nan\n",
      "Epoch[4500] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[4500] Validation-multi-accuracy_1=nan\n",
      "Epoch[4500] Validation-multi-accuracy_2=nan\n",
      "Epoch[4600] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[4600] Validation-multi-accuracy_1=nan\n",
      "Epoch[4600] Validation-multi-accuracy_2=nan\n",
      "Epoch[4700] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[4700] Validation-multi-accuracy_1=nan\n",
      "Epoch[4700] Validation-multi-accuracy_2=nan\n",
      "Epoch[4800] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[4800] Validation-multi-accuracy_1=nan\n",
      "Epoch[4800] Validation-multi-accuracy_2=nan\n",
      "Epoch[4900] Validation-multi-accuracy_0=0.965800\n",
      "Epoch[4900] Validation-multi-accuracy_1=nan\n",
      "Epoch[4900] Validation-multi-accuracy_2=nan\n",
      "Epoch[5000] Validation-multi-accuracy_0=0.965800\n",
      "Epoch[5000] Validation-multi-accuracy_1=nan\n",
      "Epoch[5000] Validation-multi-accuracy_2=nan\n",
      "Epoch[5100] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[5100] Validation-multi-accuracy_1=nan\n",
      "Epoch[5100] Validation-multi-accuracy_2=nan\n",
      "Epoch[5200] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[5200] Validation-multi-accuracy_1=nan\n",
      "Epoch[5200] Validation-multi-accuracy_2=nan\n",
      "Epoch[5300] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[5300] Validation-multi-accuracy_1=nan\n",
      "Epoch[5300] Validation-multi-accuracy_2=nan\n",
      "Epoch[5400] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[5400] Validation-multi-accuracy_1=nan\n",
      "Epoch[5400] Validation-multi-accuracy_2=nan\n",
      "Epoch[5500] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[5500] Validation-multi-accuracy_1=nan\n",
      "Epoch[5500] Validation-multi-accuracy_2=nan\n",
      "Epoch[5600] Validation-multi-accuracy_0=0.965600\n",
      "Epoch[5600] Validation-multi-accuracy_1=nan\n",
      "Epoch[5600] Validation-multi-accuracy_2=nan\n",
      "Epoch[5700] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[5700] Validation-multi-accuracy_1=nan\n",
      "Epoch[5700] Validation-multi-accuracy_2=nan\n",
      "Epoch[5800] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[5800] Validation-multi-accuracy_1=nan\n",
      "Epoch[5800] Validation-multi-accuracy_2=nan\n",
      "Epoch[5900] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[5900] Validation-multi-accuracy_1=nan\n",
      "Epoch[5900] Validation-multi-accuracy_2=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6000] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[6000] Validation-multi-accuracy_1=nan\n",
      "Epoch[6000] Validation-multi-accuracy_2=nan\n",
      "Epoch[6100] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[6100] Validation-multi-accuracy_1=nan\n",
      "Epoch[6100] Validation-multi-accuracy_2=nan\n",
      "Epoch[6200] Validation-multi-accuracy_0=0.965900\n",
      "Epoch[6200] Validation-multi-accuracy_1=nan\n",
      "Epoch[6200] Validation-multi-accuracy_2=nan\n",
      "Epoch[6300] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[6300] Validation-multi-accuracy_1=nan\n",
      "Epoch[6300] Validation-multi-accuracy_2=nan\n",
      "Epoch[6400] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[6400] Validation-multi-accuracy_1=nan\n",
      "Epoch[6400] Validation-multi-accuracy_2=nan\n",
      "Epoch[6500] Validation-multi-accuracy_0=0.966500\n",
      "Epoch[6500] Validation-multi-accuracy_1=nan\n",
      "Epoch[6500] Validation-multi-accuracy_2=nan\n",
      "Epoch[6600] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[6600] Validation-multi-accuracy_1=nan\n",
      "Epoch[6600] Validation-multi-accuracy_2=nan\n",
      "Epoch[6700] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[6700] Validation-multi-accuracy_1=nan\n",
      "Epoch[6700] Validation-multi-accuracy_2=nan\n",
      "Epoch[6800] Validation-multi-accuracy_0=0.965800\n",
      "Epoch[6800] Validation-multi-accuracy_1=nan\n",
      "Epoch[6800] Validation-multi-accuracy_2=nan\n",
      "Epoch[6900] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[6900] Validation-multi-accuracy_1=nan\n",
      "Epoch[6900] Validation-multi-accuracy_2=nan\n",
      "Epoch[7000] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[7000] Validation-multi-accuracy_1=nan\n",
      "Epoch[7000] Validation-multi-accuracy_2=nan\n",
      "Epoch[7100] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[7100] Validation-multi-accuracy_1=nan\n",
      "Epoch[7100] Validation-multi-accuracy_2=nan\n",
      "Epoch[7200] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[7200] Validation-multi-accuracy_1=nan\n",
      "Epoch[7200] Validation-multi-accuracy_2=nan\n",
      "Epoch[7300] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[7300] Validation-multi-accuracy_1=nan\n",
      "Epoch[7300] Validation-multi-accuracy_2=nan\n",
      "Epoch[7400] Validation-multi-accuracy_0=0.965800\n",
      "Epoch[7400] Validation-multi-accuracy_1=nan\n",
      "Epoch[7400] Validation-multi-accuracy_2=nan\n",
      "Epoch[7500] Validation-multi-accuracy_0=0.968300\n",
      "Epoch[7500] Validation-multi-accuracy_1=nan\n",
      "Epoch[7500] Validation-multi-accuracy_2=nan\n",
      "Epoch[7600] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[7600] Validation-multi-accuracy_1=nan\n",
      "Epoch[7600] Validation-multi-accuracy_2=nan\n",
      "Epoch[7700] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[7700] Validation-multi-accuracy_1=nan\n",
      "Epoch[7700] Validation-multi-accuracy_2=nan\n",
      "Epoch[7800] Validation-multi-accuracy_0=0.967400\n",
      "Epoch[7800] Validation-multi-accuracy_1=nan\n",
      "Epoch[7800] Validation-multi-accuracy_2=nan\n",
      "Epoch[7900] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[7900] Validation-multi-accuracy_1=nan\n",
      "Epoch[7900] Validation-multi-accuracy_2=nan\n",
      "Epoch[8000] Validation-multi-accuracy_0=0.966100\n",
      "Epoch[8000] Validation-multi-accuracy_1=nan\n",
      "Epoch[8000] Validation-multi-accuracy_2=nan\n",
      "Epoch[8100] Validation-multi-accuracy_0=0.969200\n",
      "Epoch[8100] Validation-multi-accuracy_1=nan\n",
      "Epoch[8100] Validation-multi-accuracy_2=nan\n",
      "Epoch[8200] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[8200] Validation-multi-accuracy_1=nan\n",
      "Epoch[8200] Validation-multi-accuracy_2=nan\n",
      "Epoch[8300] Validation-multi-accuracy_0=0.967000\n",
      "Epoch[8300] Validation-multi-accuracy_1=nan\n",
      "Epoch[8300] Validation-multi-accuracy_2=nan\n",
      "Epoch[8400] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[8400] Validation-multi-accuracy_1=nan\n",
      "Epoch[8400] Validation-multi-accuracy_2=nan\n",
      "Epoch[8500] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[8500] Validation-multi-accuracy_1=nan\n",
      "Epoch[8500] Validation-multi-accuracy_2=nan\n",
      "Epoch[8600] Validation-multi-accuracy_0=0.965600\n",
      "Epoch[8600] Validation-multi-accuracy_1=nan\n",
      "Epoch[8600] Validation-multi-accuracy_2=nan\n",
      "Epoch[8700] Validation-multi-accuracy_0=0.968300\n",
      "Epoch[8700] Validation-multi-accuracy_1=nan\n",
      "Epoch[8700] Validation-multi-accuracy_2=nan\n",
      "Epoch[8800] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[8800] Validation-multi-accuracy_1=nan\n",
      "Epoch[8800] Validation-multi-accuracy_2=nan\n",
      "Epoch[8900] Validation-multi-accuracy_0=0.967000\n",
      "Epoch[8900] Validation-multi-accuracy_1=nan\n",
      "Epoch[8900] Validation-multi-accuracy_2=nan\n",
      "Epoch[9000] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[9000] Validation-multi-accuracy_1=nan\n",
      "Epoch[9000] Validation-multi-accuracy_2=nan\n",
      "Epoch[9100] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[9100] Validation-multi-accuracy_1=nan\n",
      "Epoch[9100] Validation-multi-accuracy_2=nan\n",
      "Epoch[9200] Validation-multi-accuracy_0=0.965600\n",
      "Epoch[9200] Validation-multi-accuracy_1=nan\n",
      "Epoch[9200] Validation-multi-accuracy_2=nan\n",
      "Epoch[9300] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[9300] Validation-multi-accuracy_1=nan\n",
      "Epoch[9300] Validation-multi-accuracy_2=nan\n",
      "Epoch[9400] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[9400] Validation-multi-accuracy_1=nan\n",
      "Epoch[9400] Validation-multi-accuracy_2=nan\n",
      "Epoch[9500] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[9500] Validation-multi-accuracy_1=nan\n",
      "Epoch[9500] Validation-multi-accuracy_2=nan\n",
      "Epoch[9600] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[9600] Validation-multi-accuracy_1=nan\n",
      "Epoch[9600] Validation-multi-accuracy_2=nan\n",
      "Epoch[9700] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[9700] Validation-multi-accuracy_1=nan\n",
      "Epoch[9700] Validation-multi-accuracy_2=nan\n",
      "Epoch[9800] Validation-multi-accuracy_0=0.966200\n",
      "Epoch[9800] Validation-multi-accuracy_1=nan\n",
      "Epoch[9800] Validation-multi-accuracy_2=nan\n",
      "Epoch[9900] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[9900] Validation-multi-accuracy_1=nan\n",
      "Epoch[9900] Validation-multi-accuracy_2=nan\n",
      "Epoch[10000] Validation-multi-accuracy_0=0.967300\n",
      "Epoch[10000] Validation-multi-accuracy_1=nan\n",
      "Epoch[10000] Validation-multi-accuracy_2=nan\n",
      "Epoch[10100] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[10100] Validation-multi-accuracy_1=nan\n",
      "Epoch[10100] Validation-multi-accuracy_2=nan\n",
      "Epoch[10200] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[10200] Validation-multi-accuracy_1=nan\n",
      "Epoch[10200] Validation-multi-accuracy_2=nan\n",
      "Epoch[10300] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[10300] Validation-multi-accuracy_1=nan\n",
      "Epoch[10300] Validation-multi-accuracy_2=nan\n",
      "Epoch[10400] Validation-multi-accuracy_0=0.966800\n",
      "Epoch[10400] Validation-multi-accuracy_1=nan\n",
      "Epoch[10400] Validation-multi-accuracy_2=nan\n",
      "Epoch[10500] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[10500] Validation-multi-accuracy_1=nan\n",
      "Epoch[10500] Validation-multi-accuracy_2=nan\n",
      "Epoch[10600] Validation-multi-accuracy_0=0.968300\n",
      "Epoch[10600] Validation-multi-accuracy_1=nan\n",
      "Epoch[10600] Validation-multi-accuracy_2=nan\n",
      "Epoch[10700] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[10700] Validation-multi-accuracy_1=nan\n",
      "Epoch[10700] Validation-multi-accuracy_2=nan\n",
      "Epoch[10800] Validation-multi-accuracy_0=0.968400\n",
      "Epoch[10800] Validation-multi-accuracy_1=nan\n",
      "Epoch[10800] Validation-multi-accuracy_2=nan\n",
      "Epoch[10900] Validation-multi-accuracy_0=0.967400\n",
      "Epoch[10900] Validation-multi-accuracy_1=nan\n",
      "Epoch[10900] Validation-multi-accuracy_2=nan\n",
      "Epoch[11000] Validation-multi-accuracy_0=0.966400\n",
      "Epoch[11000] Validation-multi-accuracy_1=nan\n",
      "Epoch[11000] Validation-multi-accuracy_2=nan\n",
      "Epoch[11100] Validation-multi-accuracy_0=0.968400\n",
      "Epoch[11100] Validation-multi-accuracy_1=nan\n",
      "Epoch[11100] Validation-multi-accuracy_2=nan\n",
      "Epoch[11200] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[11200] Validation-multi-accuracy_1=nan\n",
      "Epoch[11200] Validation-multi-accuracy_2=nan\n",
      "Epoch[11300] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[11300] Validation-multi-accuracy_1=nan\n",
      "Epoch[11300] Validation-multi-accuracy_2=nan\n",
      "Epoch[11400] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[11400] Validation-multi-accuracy_1=nan\n",
      "Epoch[11400] Validation-multi-accuracy_2=nan\n",
      "Epoch[11500] Validation-multi-accuracy_0=0.967400\n",
      "Epoch[11500] Validation-multi-accuracy_1=nan\n",
      "Epoch[11500] Validation-multi-accuracy_2=nan\n",
      "Epoch[11600] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[11600] Validation-multi-accuracy_1=nan\n",
      "Epoch[11600] Validation-multi-accuracy_2=nan\n",
      "Epoch[11700] Validation-multi-accuracy_0=0.968400\n",
      "Epoch[11700] Validation-multi-accuracy_1=nan\n",
      "Epoch[11700] Validation-multi-accuracy_2=nan\n",
      "Epoch[11800] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[11800] Validation-multi-accuracy_1=nan\n",
      "Epoch[11800] Validation-multi-accuracy_2=nan\n",
      "Epoch[11900] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[11900] Validation-multi-accuracy_1=nan\n",
      "Epoch[11900] Validation-multi-accuracy_2=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12000] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[12000] Validation-multi-accuracy_1=nan\n",
      "Epoch[12000] Validation-multi-accuracy_2=nan\n",
      "Epoch[12100] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[12100] Validation-multi-accuracy_1=nan\n",
      "Epoch[12100] Validation-multi-accuracy_2=nan\n",
      "Epoch[12200] Validation-multi-accuracy_0=0.966400\n",
      "Epoch[12200] Validation-multi-accuracy_1=nan\n",
      "Epoch[12200] Validation-multi-accuracy_2=nan\n",
      "Epoch[12300] Validation-multi-accuracy_0=0.968400\n",
      "Epoch[12300] Validation-multi-accuracy_1=nan\n",
      "Epoch[12300] Validation-multi-accuracy_2=nan\n",
      "Epoch[12400] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[12400] Validation-multi-accuracy_1=nan\n",
      "Epoch[12400] Validation-multi-accuracy_2=nan\n",
      "Epoch[12500] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[12500] Validation-multi-accuracy_1=nan\n",
      "Epoch[12500] Validation-multi-accuracy_2=nan\n",
      "Epoch[12600] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[12600] Validation-multi-accuracy_1=nan\n",
      "Epoch[12600] Validation-multi-accuracy_2=nan\n",
      "Epoch[12700] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[12700] Validation-multi-accuracy_1=nan\n",
      "Epoch[12700] Validation-multi-accuracy_2=nan\n",
      "Epoch[12800] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[12800] Validation-multi-accuracy_1=nan\n",
      "Epoch[12800] Validation-multi-accuracy_2=nan\n",
      "Epoch[12900] Validation-multi-accuracy_0=0.968700\n",
      "Epoch[12900] Validation-multi-accuracy_1=nan\n",
      "Epoch[12900] Validation-multi-accuracy_2=nan\n",
      "Epoch[13000] Validation-multi-accuracy_0=0.968500\n",
      "Epoch[13000] Validation-multi-accuracy_1=nan\n",
      "Epoch[13000] Validation-multi-accuracy_2=nan\n",
      "Epoch[13100] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[13100] Validation-multi-accuracy_1=nan\n",
      "Epoch[13100] Validation-multi-accuracy_2=nan\n",
      "Epoch[13200] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[13200] Validation-multi-accuracy_1=nan\n",
      "Epoch[13200] Validation-multi-accuracy_2=nan\n",
      "Epoch[13300] Validation-multi-accuracy_0=0.967200\n",
      "Epoch[13300] Validation-multi-accuracy_1=nan\n",
      "Epoch[13300] Validation-multi-accuracy_2=nan\n",
      "Epoch[13400] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[13400] Validation-multi-accuracy_1=nan\n",
      "Epoch[13400] Validation-multi-accuracy_2=nan\n",
      "Epoch[13500] Validation-multi-accuracy_0=0.968400\n",
      "Epoch[13500] Validation-multi-accuracy_1=nan\n",
      "Epoch[13500] Validation-multi-accuracy_2=nan\n",
      "Epoch[13600] Validation-multi-accuracy_0=0.968300\n",
      "Epoch[13600] Validation-multi-accuracy_1=nan\n",
      "Epoch[13600] Validation-multi-accuracy_2=nan\n",
      "Epoch[13700] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[13700] Validation-multi-accuracy_1=nan\n",
      "Epoch[13700] Validation-multi-accuracy_2=nan\n",
      "Epoch[13800] Validation-multi-accuracy_0=0.968300\n",
      "Epoch[13800] Validation-multi-accuracy_1=nan\n",
      "Epoch[13800] Validation-multi-accuracy_2=nan\n",
      "Epoch[13900] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[13900] Validation-multi-accuracy_1=nan\n",
      "Epoch[13900] Validation-multi-accuracy_2=nan\n",
      "Epoch[14000] Validation-multi-accuracy_0=0.966900\n",
      "Epoch[14000] Validation-multi-accuracy_1=nan\n",
      "Epoch[14000] Validation-multi-accuracy_2=nan\n",
      "Epoch[14100] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[14100] Validation-multi-accuracy_1=nan\n",
      "Epoch[14100] Validation-multi-accuracy_2=nan\n",
      "Epoch[14200] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[14200] Validation-multi-accuracy_1=nan\n",
      "Epoch[14200] Validation-multi-accuracy_2=nan\n",
      "Epoch[14300] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[14300] Validation-multi-accuracy_1=nan\n",
      "Epoch[14300] Validation-multi-accuracy_2=nan\n",
      "Epoch[14400] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[14400] Validation-multi-accuracy_1=nan\n",
      "Epoch[14400] Validation-multi-accuracy_2=nan\n",
      "Epoch[14500] Validation-multi-accuracy_0=0.967100\n",
      "Epoch[14500] Validation-multi-accuracy_1=nan\n",
      "Epoch[14500] Validation-multi-accuracy_2=nan\n",
      "Epoch[14600] Validation-multi-accuracy_0=0.966700\n",
      "Epoch[14600] Validation-multi-accuracy_1=nan\n",
      "Epoch[14600] Validation-multi-accuracy_2=nan\n",
      "Epoch[14700] Validation-multi-accuracy_0=0.968600\n",
      "Epoch[14700] Validation-multi-accuracy_1=nan\n",
      "Epoch[14700] Validation-multi-accuracy_2=nan\n",
      "Epoch[14800] Validation-multi-accuracy_0=0.968600\n",
      "Epoch[14800] Validation-multi-accuracy_1=nan\n",
      "Epoch[14800] Validation-multi-accuracy_2=nan\n",
      "Epoch[14900] Validation-multi-accuracy_0=0.967400\n",
      "Epoch[14900] Validation-multi-accuracy_1=nan\n",
      "Epoch[14900] Validation-multi-accuracy_2=nan\n",
      "Epoch[15000] Validation-multi-accuracy_0=0.968100\n",
      "Epoch[15000] Validation-multi-accuracy_1=nan\n",
      "Epoch[15000] Validation-multi-accuracy_2=nan\n",
      "Epoch[15100] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[15100] Validation-multi-accuracy_1=nan\n",
      "Epoch[15100] Validation-multi-accuracy_2=nan\n",
      "Epoch[15200] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[15200] Validation-multi-accuracy_1=nan\n",
      "Epoch[15200] Validation-multi-accuracy_2=nan\n",
      "Epoch[15300] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[15300] Validation-multi-accuracy_1=nan\n",
      "Epoch[15300] Validation-multi-accuracy_2=nan\n",
      "Epoch[15400] Validation-multi-accuracy_0=0.968200\n",
      "Epoch[15400] Validation-multi-accuracy_1=nan\n",
      "Epoch[15400] Validation-multi-accuracy_2=nan\n",
      "Epoch[15500] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[15500] Validation-multi-accuracy_1=nan\n",
      "Epoch[15500] Validation-multi-accuracy_2=nan\n",
      "Epoch[15600] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[15600] Validation-multi-accuracy_1=nan\n",
      "Epoch[15600] Validation-multi-accuracy_2=nan\n",
      "Epoch[15700] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[15700] Validation-multi-accuracy_1=nan\n",
      "Epoch[15700] Validation-multi-accuracy_2=nan\n",
      "Epoch[15800] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[15800] Validation-multi-accuracy_1=nan\n",
      "Epoch[15800] Validation-multi-accuracy_2=nan\n",
      "Epoch[15900] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[15900] Validation-multi-accuracy_1=nan\n",
      "Epoch[15900] Validation-multi-accuracy_2=nan\n",
      "Epoch[16000] Validation-multi-accuracy_0=0.968000\n",
      "Epoch[16000] Validation-multi-accuracy_1=nan\n",
      "Epoch[16000] Validation-multi-accuracy_2=nan\n",
      "Epoch[16100] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[16100] Validation-multi-accuracy_1=nan\n",
      "Epoch[16100] Validation-multi-accuracy_2=nan\n",
      "Epoch[16200] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[16200] Validation-multi-accuracy_1=nan\n",
      "Epoch[16200] Validation-multi-accuracy_2=nan\n",
      "Epoch[16300] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[16300] Validation-multi-accuracy_1=nan\n",
      "Epoch[16300] Validation-multi-accuracy_2=nan\n",
      "Epoch[16400] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[16400] Validation-multi-accuracy_1=nan\n",
      "Epoch[16400] Validation-multi-accuracy_2=nan\n",
      "Epoch[16500] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[16500] Validation-multi-accuracy_1=nan\n",
      "Epoch[16500] Validation-multi-accuracy_2=nan\n",
      "Epoch[16600] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[16600] Validation-multi-accuracy_1=nan\n",
      "Epoch[16600] Validation-multi-accuracy_2=nan\n",
      "Epoch[16700] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[16700] Validation-multi-accuracy_1=nan\n",
      "Epoch[16700] Validation-multi-accuracy_2=nan\n",
      "Epoch[16800] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[16800] Validation-multi-accuracy_1=nan\n",
      "Epoch[16800] Validation-multi-accuracy_2=nan\n",
      "Epoch[16900] Validation-multi-accuracy_0=0.967400\n",
      "Epoch[16900] Validation-multi-accuracy_1=nan\n",
      "Epoch[16900] Validation-multi-accuracy_2=nan\n",
      "Epoch[17000] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[17000] Validation-multi-accuracy_1=nan\n",
      "Epoch[17000] Validation-multi-accuracy_2=nan\n",
      "Epoch[17100] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[17100] Validation-multi-accuracy_1=nan\n",
      "Epoch[17100] Validation-multi-accuracy_2=nan\n",
      "Epoch[17200] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[17200] Validation-multi-accuracy_1=nan\n",
      "Epoch[17200] Validation-multi-accuracy_2=nan\n",
      "Epoch[17300] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[17300] Validation-multi-accuracy_1=nan\n",
      "Epoch[17300] Validation-multi-accuracy_2=nan\n",
      "Epoch[17400] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[17400] Validation-multi-accuracy_1=nan\n",
      "Epoch[17400] Validation-multi-accuracy_2=nan\n",
      "Epoch[17500] Validation-multi-accuracy_0=0.967500\n",
      "Epoch[17500] Validation-multi-accuracy_1=nan\n",
      "Epoch[17500] Validation-multi-accuracy_2=nan\n",
      "Epoch[17600] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[17600] Validation-multi-accuracy_1=nan\n",
      "Epoch[17600] Validation-multi-accuracy_2=nan\n",
      "Epoch[17700] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[17700] Validation-multi-accuracy_1=nan\n",
      "Epoch[17700] Validation-multi-accuracy_2=nan\n",
      "Epoch[17800] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[17800] Validation-multi-accuracy_1=nan\n",
      "Epoch[17800] Validation-multi-accuracy_2=nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17900] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[17900] Validation-multi-accuracy_1=nan\n",
      "Epoch[17900] Validation-multi-accuracy_2=nan\n",
      "Epoch[18000] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[18000] Validation-multi-accuracy_1=nan\n",
      "Epoch[18000] Validation-multi-accuracy_2=nan\n",
      "Epoch[18100] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[18100] Validation-multi-accuracy_1=nan\n",
      "Epoch[18100] Validation-multi-accuracy_2=nan\n",
      "Epoch[18200] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[18200] Validation-multi-accuracy_1=nan\n",
      "Epoch[18200] Validation-multi-accuracy_2=nan\n",
      "Epoch[18300] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[18300] Validation-multi-accuracy_1=nan\n",
      "Epoch[18300] Validation-multi-accuracy_2=nan\n",
      "Epoch[18400] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[18400] Validation-multi-accuracy_1=nan\n",
      "Epoch[18400] Validation-multi-accuracy_2=nan\n",
      "Epoch[18500] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[18500] Validation-multi-accuracy_1=nan\n",
      "Epoch[18500] Validation-multi-accuracy_2=nan\n",
      "Epoch[18600] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[18600] Validation-multi-accuracy_1=nan\n",
      "Epoch[18600] Validation-multi-accuracy_2=nan\n",
      "Epoch[18700] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[18700] Validation-multi-accuracy_1=nan\n",
      "Epoch[18700] Validation-multi-accuracy_2=nan\n",
      "Epoch[18800] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[18800] Validation-multi-accuracy_1=nan\n",
      "Epoch[18800] Validation-multi-accuracy_2=nan\n",
      "Epoch[18900] Validation-multi-accuracy_0=0.967600\n",
      "Epoch[18900] Validation-multi-accuracy_1=nan\n",
      "Epoch[18900] Validation-multi-accuracy_2=nan\n",
      "Epoch[19000] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[19000] Validation-multi-accuracy_1=nan\n",
      "Epoch[19000] Validation-multi-accuracy_2=nan\n",
      "Epoch[19100] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[19100] Validation-multi-accuracy_1=nan\n",
      "Epoch[19100] Validation-multi-accuracy_2=nan\n",
      "Epoch[19200] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19200] Validation-multi-accuracy_1=nan\n",
      "Epoch[19200] Validation-multi-accuracy_2=nan\n",
      "Epoch[19300] Validation-multi-accuracy_0=0.967800\n",
      "Epoch[19300] Validation-multi-accuracy_1=nan\n",
      "Epoch[19300] Validation-multi-accuracy_2=nan\n",
      "Epoch[19400] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19400] Validation-multi-accuracy_1=nan\n",
      "Epoch[19400] Validation-multi-accuracy_2=nan\n",
      "Epoch[19500] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19500] Validation-multi-accuracy_1=nan\n",
      "Epoch[19500] Validation-multi-accuracy_2=nan\n",
      "Epoch[19600] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19600] Validation-multi-accuracy_1=nan\n",
      "Epoch[19600] Validation-multi-accuracy_2=nan\n",
      "Epoch[19700] Validation-multi-accuracy_0=0.967900\n",
      "Epoch[19700] Validation-multi-accuracy_1=nan\n",
      "Epoch[19700] Validation-multi-accuracy_2=nan\n",
      "Epoch[19800] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19800] Validation-multi-accuracy_1=nan\n",
      "Epoch[19800] Validation-multi-accuracy_2=nan\n",
      "Epoch[19900] Validation-multi-accuracy_0=0.967700\n",
      "Epoch[19900] Validation-multi-accuracy_1=nan\n",
      "Epoch[19900] Validation-multi-accuracy_2=nan\n"
     ]
    }
   ],
   "source": [
    "train_sup.reset()\n",
    "train_unsup.reset()\n",
    "\n",
    "net = build()\n",
    "\n",
    "model = fit_model(args, net, (train, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape={\"dataSup\":(10, 1, 28,28),\n",
    "                    \"dataUnsup0\":(10, 1, 28,28),\n",
    "                    \"dataUnsup1\":(10, 1, 28,28), \n",
    "                     \"labelSup\": (10)\n",
    "                    }\n",
    "\n",
    "plot_network(net, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch=train.next()\n",
    "\n",
    "labels = batch.label[0]\n",
    "bDataSup = batch.data[0]\n",
    "bDataUnsup = batch.data[1]\n",
    "\n",
    "\n",
    "a = model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 976,    0,    2,    0,    0,    0,    0,    1,    1,    0],\n",
       "       [   0, 1123,    5,    3,    0,    1,    0,    3,    0,    0],\n",
       "       [   1,    0, 1029,    0,    0,    0,    0,    1,    0,    1],\n",
       "       [   0,    0,    0, 1001,    0,    4,    0,    2,    2,    1],\n",
       "       [   1,    0,    0,    0,  955,    0,    2,    0,    0,   24],\n",
       "       [   0,    0,    0,    2,    0,  887,    2,    1,    0,    0],\n",
       "       [   5,    3,    1,    0,    1,    3,  944,    0,    1,    0],\n",
       "       [   0,    1,    8,    1,    0,    1,    0, 1016,    0,    1],\n",
       "       [   0,    0,    1,    2,    1,    1,    0,    2,  964,    3],\n",
       "       [   2,    0,    0,    2,    9,    2,    0,   10,    0,  984]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix(labels, predictions, num_labels):\n",
    "  \"\"\"Compute the confusion matrix.\"\"\"\n",
    "  rows = []\n",
    "  for i in range(num_labels):\n",
    "    row = np.bincount(predictions[labels == i], minlength=num_labels)\n",
    "    rows.append(row)\n",
    "  return np.vstack(rows)\n",
    "\n",
    "val.reset()\n",
    "res = model.predict(val)[0].asnumpy().argmax(axis=1)\n",
    "print(res.shape, val_lbl.shape)\n",
    "\n",
    "confusion_matrix(val_lbl, res,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(labels.asnumpy())\n",
    "model.get_outputs()[1].asnumpy()[0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import json\n",
    "def _str2tuple(string):\n",
    "    \"\"\"Convert shape string to list, internal use only.\n",
    "    Parameters\n",
    "    ----------\n",
    "    string: str\n",
    "        Shape string.\n",
    "    Returns\n",
    "    -------\n",
    "    list of str\n",
    "        Represents shape.\n",
    "    \"\"\"\n",
    "    return re.findall(r\"\\d+\", string)\n",
    "\n",
    "def plot_network(symbol, title=\"plot\", save_format='pdf', shape=None, node_attrs={},\n",
    "                 hide_weights=True):\n",
    "    \"\"\"Creates a visualization (Graphviz digraph object) of the given computation graph.\n",
    "    Graphviz must be installed for this function to work.\n",
    "    Parameters\n",
    "    ----------\n",
    "    title: str, optional\n",
    "        Title of the generated visualization.\n",
    "    symbol: Symbol\n",
    "        A symbol from the computation graph. The generated digraph will visualize the part\n",
    "        of the computation graph required to compute `symbol`.\n",
    "    shape: dict, optional\n",
    "        Specifies the shape of the input tensors. If specified, the visualization will include\n",
    "        the shape of the tensors between the nodes. `shape` is a dictionary mapping\n",
    "        input symbol names (str) to the corresponding tensor shape (tuple).\n",
    "    node_attrs: dict, optional\n",
    "        Specifies the attributes for nodes in the generated visualization. `node_attrs` is\n",
    "        a dictionary of Graphviz attribute names and values. For example,\n",
    "            ``node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}``\n",
    "            will use oval shape for nodes and allow variable sized nodes in the visualization.\n",
    "    hide_weights: bool, optional\n",
    "        If True (default), then inputs with names of form *_weight (corresponding to weight\n",
    "        tensors) or *_bias (corresponding to bias vectors) will be hidden for a cleaner\n",
    "        visualization.\n",
    "    Returns\n",
    "    -------\n",
    "    dot: Digraph\n",
    "        A Graphviz digraph object visualizing the computation graph to compute `symbol`.\n",
    "    Example\n",
    "    -------\n",
    "    >>> net = mx.sym.Variable('data')\n",
    "    >>> net = mx.sym.FullyConnected(data=net, name='fc1', num_hidden=128)\n",
    "    >>> net = mx.sym.Activation(data=net, name='relu1', act_type=\"relu\")\n",
    "    >>> net = mx.sym.FullyConnected(data=net, name='fc2', num_hidden=10)\n",
    "    >>> net = mx.sym.SoftmaxOutput(data=net, name='out')\n",
    "    >>> digraph = mx.viz.plot_network(net, shape={'data':(100,200)},\n",
    "    ... node_attrs={\"fixedsize\":\"false\"})\n",
    "    >>> digraph.view()\n",
    "    \"\"\"\n",
    "    # todo add shape support\n",
    "    try:\n",
    "        from graphviz import Digraph\n",
    "    except:\n",
    "        raise ImportError(\"Draw network requires graphviz library\")\n",
    "    if not isinstance(symbol, Symbol):\n",
    "        raise TypeError(\"symbol must be a Symbol\")\n",
    "    draw_shape = False\n",
    "    if shape is not None:\n",
    "        draw_shape = True\n",
    "        interals = symbol.get_internals()\n",
    "        _, out_shapes, _ = interals.infer_shape(**shape)\n",
    "        if out_shapes is None:\n",
    "            raise ValueError(\"Input shape is incomplete\")\n",
    "        shape_dict = dict(zip(interals.list_outputs(), out_shapes))\n",
    "    conf = json.loads(symbol.tojson())\n",
    "    nodes = conf[\"nodes\"]\n",
    "    # default attributes of node\n",
    "    node_attr = {\"shape\": \"box\", \"fixedsize\": \"true\",\n",
    "                 \"width\": \"1.3\", \"height\": \"0.8034\", \"style\": \"filled\"}\n",
    "    # merge the dict provided by user and the default one\n",
    "    node_attr.update(node_attrs)\n",
    "    dot = Digraph(name=title, format=save_format)\n",
    "    # color map\n",
    "    cm = (\"#8dd3c7\", \"#fb8072\", \"#ffffb3\", \"#bebada\", \"#80b1d3\",\n",
    "          \"#fdb462\", \"#b3de69\", \"#fccde5\")\n",
    "\n",
    "    def looks_like_weight(name):\n",
    "        \"\"\"Internal helper to figure out if node should be hidden with `hide_weights`.\n",
    "        \"\"\"\n",
    "        if name.endswith(\"_weight\"):\n",
    "            return True\n",
    "        if name.endswith(\"_bias\"):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # make nodes\n",
    "    hidden_nodes = set()\n",
    "    for node in nodes:\n",
    "        op = node[\"op\"]\n",
    "        name = node[\"name\"]\n",
    "        # input data\n",
    "        attr = copy.deepcopy(node_attr)\n",
    "        label = name\n",
    "\n",
    "        if op == \"null\":\n",
    "            if looks_like_weight(node[\"name\"]):\n",
    "                if hide_weights:\n",
    "                    hidden_nodes.add(node[\"name\"])\n",
    "                # else we don't render a node, but\n",
    "                # don't add it to the hidden_nodes set\n",
    "                # so it gets rendered as an empty oval\n",
    "                continue\n",
    "            attr[\"shape\"] = \"oval\" # inputs get their own shape\n",
    "            label = node[\"name\"]\n",
    "            attr[\"fillcolor\"] = cm[0]\n",
    "        elif op == \"Convolution\":\n",
    "            label = r\"Convolution\\n%s/%s, %s\" % (\"x\".join(_str2tuple(node[\"attr\"][\"kernel\"])),\n",
    "                                                 \"x\".join(_str2tuple(node[\"attr\"][\"stride\"]))\n",
    "                                                 if \"stride\" in node[\"attr\"] else \"1\",\n",
    "                                                 node[\"attr\"][\"num_filter\"])\n",
    "            attr[\"fillcolor\"] = cm[1]\n",
    "        elif op == \"FullyConnected\":\n",
    "            label = r\"FullyConnected\\n%s\" % node[\"attr\"][\"num_hidden\"]\n",
    "            attr[\"fillcolor\"] = cm[1]\n",
    "        elif op == \"BatchNorm\":\n",
    "            attr[\"fillcolor\"] = cm[3]\n",
    "        elif op == \"Activation\" or op == \"LeakyReLU\":\n",
    "            label = r\"%s\\n%s\" % (op, node[\"attr\"][\"act_type\"])\n",
    "            attr[\"fillcolor\"] = cm[2]\n",
    "        elif op == \"Pooling\":\n",
    "            label = r\"Pooling\\n%s, %s/%s\" % (node[\"attr\"][\"pool_type\"],\n",
    "                                             \"x\".join(_str2tuple(node[\"attr\"][\"kernel\"])),\n",
    "                                             \"x\".join(_str2tuple(node[\"attr\"][\"stride\"]))\n",
    "                                             if \"stride\" in node[\"attr\"] else \"1\")\n",
    "            attr[\"fillcolor\"] = cm[4]\n",
    "        elif op == \"Concat\" or op == \"Flatten\" or op == \"Reshape\":\n",
    "            attr[\"fillcolor\"] = cm[5]\n",
    "        elif op == \"Softmax\":\n",
    "            attr[\"fillcolor\"] = cm[6]\n",
    "        else:\n",
    "            attr[\"fillcolor\"] = cm[7]\n",
    "            if op == \"Custom\":\n",
    "                label = node[\"attr\"][\"op_type\"]\n",
    "\n",
    "        dot.node(name=name, label=label, **attr)\n",
    "\n",
    "    # add edges\n",
    "    for node in nodes:          # pylint: disable=too-many-nested-blocks\n",
    "        op = node[\"op\"]\n",
    "        name = node[\"name\"]\n",
    "        if op == \"null\":\n",
    "            continue\n",
    "        else:\n",
    "            inputs = node[\"inputs\"]\n",
    "            for item in inputs:\n",
    "                input_node = nodes[item[0]]\n",
    "                input_name = input_node[\"name\"]\n",
    "                if input_name not in hidden_nodes:\n",
    "                    attr = {\"dir\": \"back\", 'arrowtail':'open'}\n",
    "                    # add shapes\n",
    "                    if draw_shape:\n",
    "                        if input_node[\"op\"] != \"null\":\n",
    "                            key = input_name + \"_output\"\n",
    "                            if \"attr\" in input_node:\n",
    "                                params = input_node[\"attr\"]\n",
    "                                if \"num_outputs\" in params:\n",
    "                                    key += str(np.maximum(int(params[\"num_outputs\"]) - 1, 0))\n",
    "                                    params[\"num_outputs\"] = int(params[\"num_outputs\"]) - 1\n",
    "                            shape = shape_dict[key][1:]\n",
    "                            label = \"x\".join([str(x) for x in shape])\n",
    "                            attr[\"label\"] = label\n",
    "                        else:\n",
    "                            key = input_name\n",
    "                            shape = shape_dict[key][1:]\n",
    "                            label = \"x\".join([str(x) for x in shape])\n",
    "                            attr[\"label\"] = label\n",
    "                    dot.edge(tail_name=name, head_name=input_name, **attr)\n",
    "\n",
    "    return dot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
